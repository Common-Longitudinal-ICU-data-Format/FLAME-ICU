{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICU Mortality Model - Cohort Generation\n",
    "\n",
    "This notebook generates the ICU cohort for mortality prediction modeling following the PRD requirements.\n",
    "\n",
    "## Objective\n",
    "Generate a cohort table containing:\n",
    "- `hospitalization_id`\n",
    "- `start_dttm`: ICU admission timestamp\n",
    "- `hour_24_start_dttm`: first ICU hour (may equal start_dttm)\n",
    "- `hour_24_end_dttm`: end of the first 24 hours\n",
    "- `disposition`: binary outcome (1 = expired, 0 = survived)\n",
    "\n",
    "## Cohort Criteria\n",
    "- First 24 hours of first ICU stay\n",
    "- Exclude re-admissions and ICU readmissions\n",
    "- ICU-OR-ICU sequences treated as continuous ICU stay\n",
    "- Minimum 24-hour ICU stay\n",
    "- Adults (≥18 years)\n",
    "- 2020-2021 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ICU Mortality Model - Cohort Generation ===\n",
      "Setting up environment...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyclif import CLIF\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== ICU Mortality Model - Cohort Generation ===\")\n",
    "print(\"Setting up environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded configuration from config.json\n",
      "Site: MIMIC\n",
      "Data path: /Users/sudo_sage/Documents/WORK/clif_mimic\n",
      "File type: parquet\n"
     ]
    }
   ],
   "source": [
    "def load_config():\n",
    "    \"\"\"Load configuration from config.json\"\"\"\n",
    "    config_path = os.path.join( \"config_demo.json\")\n",
    "    \n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = json.load(file)\n",
    "        print(\"✅ Loaded configuration from config.json\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Configuration file not found. Please create config.json based on the config_template.\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Load configuration\n",
    "config = load_config()\n",
    "print(f\"Site: {config['site']}\")\n",
    "print(f\"Data path: {config['clif2_path']}\")\n",
    "print(f\"File type: {config['filetype']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIF Object Initialized.\n",
      "✅ pyCLIF initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize pyCLIF\n",
    "clif = CLIF(\n",
    "    data_dir=config['clif2_path'],\n",
    "    filetype=config['filetype'],\n",
    "    timezone=\"US/Eastern\"\n",
    ")\n",
    "\n",
    "print(\"✅ pyCLIF initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required tables...\n",
      "Loading clif_adt.parquet\n",
      "Data loaded successfully from clif_adt.parquet\n",
      "Validation completed with 3 error(s). See `errors` attribute.\n",
      "Loading clif_hospitalization.parquet\n",
      "Data loaded successfully from clif_hospitalization.parquet\n",
      "Validation completed with 1 error(s). See `errors` attribute.\n",
      "Loading clif_patient.parquet\n",
      "Data loaded successfully from clif_patient.parquet\n",
      "Validation completed with 8 error(s). See `errors` attribute.\n",
      "ADT data loaded: 1458408 records\n",
      "Hospitalization data loaded: 546028 records\n",
      "Patient data loaded: 364627 records\n"
     ]
    }
   ],
   "source": [
    "# Load required tables using pyCLIF\n",
    "print(\"Loading required tables...\")\n",
    "clif.initialize([\"adt\", \"hospitalization\", \"patient\"])\n",
    "\n",
    "# Load ADT data\n",
    "adt_df = clif.adt.df.copy()\n",
    "print(f\"ADT data loaded: {len(adt_df)} records\")\n",
    "\n",
    "# Load hospitalization data\n",
    "hosp_df = clif.hospitalization.df.copy()\n",
    "print(f\"Hospitalization data loaded: {len(hosp_df)} records\")\n",
    "\n",
    "# Load patient data\n",
    "patient_df = clif.patient.df.copy()\n",
    "print(f\"Patient data loaded: {len(patient_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_category\n",
       "ward          640846\n",
       "ed            476770\n",
       "icu           118077\n",
       "other          71399\n",
       "stepdown       70482\n",
       "procedural     34958\n",
       "l&d            29003\n",
       "psych          16873\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adt_df.location_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for cohort generation...\n",
      "Merged data: 1458408 records\n",
      "✅ Data preparation completed\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for cohort generation\n",
    "print(\"Preparing data for cohort generation...\")\n",
    "\n",
    "# Merge ADT with hospitalization data\n",
    "icu_data = pd.merge(\n",
    "    adt_df[['hospitalization_id', 'location_category', 'in_dttm', 'out_dttm']],\n",
    "    hosp_df[['patient_id', 'hospitalization_id', 'age_at_admission', 'discharge_category', 'admission_dttm']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged data: {len(icu_data)} records\")\n",
    "\n",
    "# Convert datetime columns\n",
    "datetime_cols = ['in_dttm', 'out_dttm', 'admission_dttm']\n",
    "for col in datetime_cols:\n",
    "    icu_data[col] = pd.to_datetime(icu_data[col])\n",
    "\n",
    "# Handle location categories (convert procedural to OR as in Inference_py.ipynb)\n",
    "icu_data.loc[icu_data['location_category'] == 'procedural', 'location_category'] = 'OR'\n",
    "icu_data['location_category'] = icu_data['location_category'].str.upper()\n",
    "\n",
    "print(\"✅ Data preparation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICU Cohort Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalization_id</th>\n",
       "      <th>location_category</th>\n",
       "      <th>in_dttm</th>\n",
       "      <th>out_dttm</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_at_admission</th>\n",
       "      <th>discharge_category</th>\n",
       "      <th>admission_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22595853</td>\n",
       "      <td>ED</td>\n",
       "      <td>2180-05-07 00:17:00+00:00</td>\n",
       "      <td>2180-05-07 04:30:00+00:00</td>\n",
       "      <td>10000032</td>\n",
       "      <td>52</td>\n",
       "      <td>Home</td>\n",
       "      <td>2180-05-07 03:23:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22595853</td>\n",
       "      <td>WARD</td>\n",
       "      <td>2180-05-07 04:30:00+00:00</td>\n",
       "      <td>2180-05-07 22:21:27+00:00</td>\n",
       "      <td>10000032</td>\n",
       "      <td>52</td>\n",
       "      <td>Home</td>\n",
       "      <td>2180-05-07 03:23:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22841357</td>\n",
       "      <td>WARD</td>\n",
       "      <td>2180-06-27 02:31:00+00:00</td>\n",
       "      <td>2180-06-27 23:49:12+00:00</td>\n",
       "      <td>10000032</td>\n",
       "      <td>52</td>\n",
       "      <td>Home</td>\n",
       "      <td>2180-06-26 23:27:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22841357</td>\n",
       "      <td>ED</td>\n",
       "      <td>2180-06-26 20:54:00+00:00</td>\n",
       "      <td>2180-06-27 02:31:00+00:00</td>\n",
       "      <td>10000032</td>\n",
       "      <td>52</td>\n",
       "      <td>Home</td>\n",
       "      <td>2180-06-26 23:27:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25742920</td>\n",
       "      <td>WARD</td>\n",
       "      <td>2180-08-06 06:44:00+00:00</td>\n",
       "      <td>2180-08-07 22:50:44+00:00</td>\n",
       "      <td>10000032</td>\n",
       "      <td>52</td>\n",
       "      <td>Hospice</td>\n",
       "      <td>2180-08-06 04:44:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hospitalization_id location_category                   in_dttm  \\\n",
       "0           22595853                ED 2180-05-07 00:17:00+00:00   \n",
       "1           22595853              WARD 2180-05-07 04:30:00+00:00   \n",
       "2           22841357              WARD 2180-06-27 02:31:00+00:00   \n",
       "3           22841357                ED 2180-06-26 20:54:00+00:00   \n",
       "4           25742920              WARD 2180-08-06 06:44:00+00:00   \n",
       "\n",
       "                   out_dttm patient_id  age_at_admission discharge_category  \\\n",
       "0 2180-05-07 04:30:00+00:00   10000032                52               Home   \n",
       "1 2180-05-07 22:21:27+00:00   10000032                52               Home   \n",
       "2 2180-06-27 23:49:12+00:00   10000032                52               Home   \n",
       "3 2180-06-27 02:31:00+00:00   10000032                52               Home   \n",
       "4 2180-08-07 22:50:44+00:00   10000032                52            Hospice   \n",
       "\n",
       "             admission_dttm  \n",
       "0 2180-05-07 03:23:00+00:00  \n",
       "1 2180-05-07 03:23:00+00:00  \n",
       "2 2180-06-26 23:27:00+00:00  \n",
       "3 2180-06-26 23:27:00+00:00  \n",
       "4 2180-08-06 04:44:00+00:00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying initial cohort filters...\n",
      "Hospitalizations with ICU within 48hr: 73430\n",
      "Filtered data for processing: 237855 records\n"
     ]
    }
   ],
   "source": [
    "# Apply initial filters\n",
    "print(\"Applying initial cohort filters...\")\n",
    "\n",
    "# Filter for ICU admissions within 48 hours of hospital admission\n",
    "icu_48hr_check = icu_data[\n",
    "    (icu_data['location_category'] == 'ICU') &\n",
    "    (icu_data['in_dttm'] >= icu_data['admission_dttm']) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=48)) &\n",
    "   # (icu_data['admission_dttm'].dt.year >= 2020) & (icu_data['admission_dttm'].dt.year <= 2021) &\n",
    "    (icu_data['age_at_admission'] >= 18) & (icu_data['age_at_admission'].notna())\n",
    "]['hospitalization_id'].unique()\n",
    "\n",
    "print(f\"Hospitalizations with ICU within 48hr: {len(icu_48hr_check)}\")\n",
    "\n",
    "# Filter to relevant encounters and extend to 72 hours for location tracking\n",
    "icu_data = icu_data[\n",
    "    icu_data['hospitalization_id'].isin(icu_48hr_check) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=72))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"Filtered data for processing: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ICU-OR-ICU sequences...\n",
      "After ICU-OR-ICU processing: 148501 records\n"
     ]
    }
   ],
   "source": [
    "# Process ICU-OR-ICU sequences (treat as continuous ICU)\n",
    "print(\"Processing ICU-OR-ICU sequences...\")\n",
    "\n",
    "# Sort by admission time and create ranking\n",
    "icu_data = icu_data.sort_values(by=['in_dttm']).reset_index(drop=True)\n",
    "icu_data[\"RANK\"] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(\"hospitalization_id\")[\"in_dttm\"].rank(method=\"first\", ascending=True).astype(int)\n",
    "\n",
    "# Find minimum ICU rank for each hospitalization\n",
    "min_icu = icu_data[icu_data['location_category'] == 'ICU'].groupby('hospitalization_id')['RANK'].min()\n",
    "icu_data = pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['hospitalization_id', 'min_icu']), on='hospitalization_id', how='left')\n",
    "\n",
    "# Filter to locations from first ICU onward\n",
    "icu_data = icu_data[icu_data['RANK'] >= icu_data['min_icu']].reset_index(drop=True)\n",
    "\n",
    "# Convert OR to ICU for continuity (ICU-OR-ICU treated as continuous ICU)\n",
    "icu_data.loc[icu_data['location_category'] == 'OR', 'location_category'] = 'ICU'\n",
    "\n",
    "print(f\"After ICU-OR-ICU processing: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping consecutive ICU locations...\n",
      "Grouped data: 125005 records\n"
     ]
    }
   ],
   "source": [
    "# Group consecutive ICU locations\n",
    "print(\"Grouping consecutive ICU locations...\")\n",
    "\n",
    "# Create groups for consecutive locations\n",
    "icu_data['group_id'] = (icu_data.groupby('hospitalization_id')['location_category'].shift() != icu_data['location_category']).astype(int)\n",
    "icu_data['group_id'] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby('hospitalization_id')['group_id'].cumsum()\n",
    "\n",
    "# Aggregate by groups\n",
    "icu_data = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(['patient_id', 'hospitalization_id', 'location_category', 'group_id']).agg(\n",
    "    min_in_dttm=('in_dttm', 'min'),\n",
    "    max_out_dttm=('out_dttm', 'max'),\n",
    "    admission_dttm=('admission_dttm', 'first'),\n",
    "    age=('age_at_admission', 'first'),\n",
    "    dispo=('discharge_category', 'first')\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Grouped data: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying final cohort criteria...\n",
      "Final cohort before demographics: 54509 records\n",
      "✅ ICU cohort criteria applied\n"
     ]
    }
   ],
   "source": [
    "# Apply final cohort criteria\n",
    "print(\"Applying final cohort criteria...\")\n",
    "\n",
    "# Find minimum ICU group for each hospitalization\n",
    "min_icu_group = icu_data[icu_data['location_category'] == 'ICU'].groupby('hospitalization_id')['group_id'].min()\n",
    "icu_data = pd.merge(icu_data, pd.DataFrame(zip(min_icu_group.index, min_icu_group.values), columns=['hospitalization_id', 'min_icu_group']), on='hospitalization_id', how='left')\n",
    "\n",
    "# Filter to first ICU stay with minimum 24-hour duration\n",
    "icu_data = icu_data[\n",
    "    (icu_data['min_icu_group'] == icu_data['group_id']) &\n",
    "    (icu_data['max_out_dttm'] - icu_data['min_in_dttm'] >= pd.Timedelta(hours=24))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final cohort before demographics: {len(icu_data)} records\")\n",
    "\n",
    "# Add 24-hour endpoint\n",
    "icu_data['after_24hr'] = icu_data['min_in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "# Select required columns\n",
    "icu_data = icu_data[['patient_id', 'hospitalization_id', 'min_in_dttm', 'max_out_dttm', 'after_24hr', 'age', 'dispo']]\n",
    "\n",
    "print(\"✅ ICU cohort criteria applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Demographics and Create Final Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding patient demographics...\n",
      "Final cohort with demographics: 54509 records\n"
     ]
    }
   ],
   "source": [
    "# Add patient demographics\n",
    "print(\"Adding patient demographics...\")\n",
    "\n",
    "# Rename columns for consistency with CLIF 2.0\n",
    "patient_df_clean = patient_df.rename(columns={\n",
    "    'race_category': 'race',\n",
    "    'ethnicity_category': 'ethnicity',\n",
    "    'sex_category': 'sex'\n",
    "})\n",
    "\n",
    "# Merge with patient data\n",
    "icu_data = pd.merge(\n",
    "    icu_data,\n",
    "    patient_df_clean[['patient_id', 'sex', 'ethnicity', 'race']],\n",
    "    on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filter out records with missing sex (data quality)\n",
    "icu_data = icu_data[~icu_data['sex'].isna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final cohort with demographics: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospitalization_id</th>\n",
       "      <th>min_in_dttm</th>\n",
       "      <th>max_out_dttm</th>\n",
       "      <th>after_24hr</th>\n",
       "      <th>age</th>\n",
       "      <th>dispo</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000690</td>\n",
       "      <td>25860671</td>\n",
       "      <td>2150-11-03 00:37:00+00:00</td>\n",
       "      <td>2150-11-06 22:03:17+00:00</td>\n",
       "      <td>2150-11-04 00:37:00+00:00</td>\n",
       "      <td>86</td>\n",
       "      <td>Acute Inpatient Rehab Facility</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001217</td>\n",
       "      <td>24597018</td>\n",
       "      <td>2157-11-21 00:18:02+00:00</td>\n",
       "      <td>2157-11-22 03:08:00+00:00</td>\n",
       "      <td>2157-11-22 00:18:02+00:00</td>\n",
       "      <td>55</td>\n",
       "      <td>Home</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001725</td>\n",
       "      <td>25563031</td>\n",
       "      <td>2110-04-11 20:52:22+00:00</td>\n",
       "      <td>2110-04-13 04:59:56+00:00</td>\n",
       "      <td>2110-04-12 20:52:22+00:00</td>\n",
       "      <td>46</td>\n",
       "      <td>Home</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002013</td>\n",
       "      <td>23581541</td>\n",
       "      <td>2160-05-18 15:00:53+00:00</td>\n",
       "      <td>2160-05-19 22:33:33+00:00</td>\n",
       "      <td>2160-05-19 15:00:53+00:00</td>\n",
       "      <td>57</td>\n",
       "      <td>Home</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002114</td>\n",
       "      <td>27793700</td>\n",
       "      <td>2162-02-18 04:30:00+00:00</td>\n",
       "      <td>2162-02-21 02:16:27+00:00</td>\n",
       "      <td>2162-02-19 04:30:00+00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>Home</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id hospitalization_id               min_in_dttm  \\\n",
       "0   10000690           25860671 2150-11-03 00:37:00+00:00   \n",
       "1   10001217           24597018 2157-11-21 00:18:02+00:00   \n",
       "2   10001725           25563031 2110-04-11 20:52:22+00:00   \n",
       "3   10002013           23581541 2160-05-18 15:00:53+00:00   \n",
       "4   10002114           27793700 2162-02-18 04:30:00+00:00   \n",
       "\n",
       "               max_out_dttm                after_24hr  age  \\\n",
       "0 2150-11-06 22:03:17+00:00 2150-11-04 00:37:00+00:00   86   \n",
       "1 2157-11-22 03:08:00+00:00 2157-11-22 00:18:02+00:00   55   \n",
       "2 2110-04-13 04:59:56+00:00 2110-04-12 20:52:22+00:00   46   \n",
       "3 2160-05-19 22:33:33+00:00 2160-05-19 15:00:53+00:00   57   \n",
       "4 2162-02-21 02:16:27+00:00 2162-02-19 04:30:00+00:00   56   \n",
       "\n",
       "                            dispo     sex     ethnicity     race  \n",
       "0  Acute Inpatient Rehab Facility  Female  Non-Hispanic    White  \n",
       "1                            Home  Female  Non-Hispanic    White  \n",
       "2                            Home  Female  Non-Hispanic    White  \n",
       "3                            Home  Female  Non-Hispanic    White  \n",
       "4                            Home    Male       Unknown  Unknown  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final cohort table...\n",
      "✅ Final cohort created: 54509 hospitalizations\n",
      "Mortality rate: 0.110\n"
     ]
    }
   ],
   "source": [
    "# Create final cohort table with required columns\n",
    "print(\"Creating final cohort table...\")\n",
    "\n",
    "# Create disposition binary variable (1 = expired, 0 = survived)\n",
    "icu_data['disposition'] = (icu_data['dispo'].fillna('Other').str.contains('dead|expired|death|died', case=False, regex=True)).astype(int)\n",
    "\n",
    "# Create final cohort with PRD required columns\n",
    "cohort_final = icu_data[[\n",
    "    'hospitalization_id',\n",
    "    'min_in_dttm',     # start_dttm\n",
    "    'after_24hr',      # hour_24_end_dttm\n",
    "    'disposition'\n",
    "]].rename(columns={\n",
    "    'min_in_dttm': 'start_dttm',\n",
    "    'after_24hr': 'hour_24_end_dttm'\n",
    "})\n",
    "\n",
    "# Add hour_24_start_dttm (same as start_dttm for our cohort)\n",
    "cohort_final['hour_24_start_dttm'] = cohort_final['start_dttm']\n",
    "\n",
    "# Reorder columns as per PRD\n",
    "cohort_final = cohort_final[[\n",
    "    'hospitalization_id',\n",
    "    'start_dttm',\n",
    "    'hour_24_start_dttm',\n",
    "    'hour_24_end_dttm',\n",
    "    'disposition'\n",
    "]]\n",
    "\n",
    "print(f\"✅ Final cohort created: {len(cohort_final)} hospitalizations\")\n",
    "print(f\"Mortality rate: {cohort_final['disposition'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disposition\n",
       "0    88.96696\n",
       "1    11.03304\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_final['disposition'].value_counts()*100/cohort_final.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Summary and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ICU Cohort Summary ===\n",
      "Total hospitalizations: 54,509\n",
      "Mortality rate: 0.110 (6,014 deaths)\n",
      "Survival rate: 0.890 (48,495 survivors)\n",
      "\n",
      "=== Time Range Analysis ===\n",
      "Cohort start date: 2105-10-04 22:27:12+00:00\n",
      "Cohort end date: 2214-05-03 22:09:18+00:00\n",
      "24-hour window duration: 1 days 00:00:00\n",
      "\n",
      "=== Validation Checks ===\n",
      "All 24-hour windows are exactly 24 hours: True\n",
      "No missing hospitalization IDs: True\n",
      "All start times before end times: True\n"
     ]
    }
   ],
   "source": [
    "# Display cohort summary\n",
    "print(\"=== ICU Cohort Summary ===\")\n",
    "print(f\"Total hospitalizations: {len(cohort_final):,}\")\n",
    "print(f\"Mortality rate: {cohort_final['disposition'].mean():.3f} ({cohort_final['disposition'].sum():,} deaths)\")\n",
    "print(f\"Survival rate: {1 - cohort_final['disposition'].mean():.3f} ({(cohort_final['disposition'] == 0).sum():,} survivors)\")\n",
    "\n",
    "# Time range analysis\n",
    "print(f\"\\n=== Time Range Analysis ===\")\n",
    "print(f\"Cohort start date: {cohort_final['start_dttm'].min()}\")\n",
    "print(f\"Cohort end date: {cohort_final['start_dttm'].max()}\")\n",
    "print(f\"24-hour window duration: {(cohort_final['hour_24_end_dttm'] - cohort_final['hour_24_start_dttm']).iloc[0]}\")\n",
    "\n",
    "# Validation checks\n",
    "print(f\"\\n=== Validation Checks ===\")\n",
    "print(f\"All 24-hour windows are exactly 24 hours: {((cohort_final['hour_24_end_dttm'] - cohort_final['hour_24_start_dttm']).dt.total_seconds() == 24*3600).all()}\")\n",
    "print(f\"No missing hospitalization IDs: {cohort_final['hospitalization_id'].isna().sum() == 0}\")\n",
    "print(f\"All start times before end times: {(cohort_final['start_dttm'] <= cohort_final['hour_24_end_dttm']).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Cohort to Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cohort saved to: ../output/preprocessing/icu_cohort.parquet\n",
      "File size: 2091.1 KB\n",
      "Shape: (54509, 5)\n",
      "✅ Metadata saved to: ../output/preprocessing/cohort_metadata.json\n",
      "\n",
      "🎉 Cohort generation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save cohort to output/preprocessing directory\n",
    "output_path = os.path.join('..', 'output', 'preprocessing', 'icu_cohort.parquet')\n",
    "cohort_final.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Cohort saved to: {output_path}\")\n",
    "print(f\"File size: {os.path.getsize(output_path) / 1024:.1f} KB\")\n",
    "print(f\"Shape: {cohort_final.shape}\")\n",
    "\n",
    "# Save additional metadata\n",
    "metadata = {\n",
    "    'cohort_size': len(cohort_final),\n",
    "    'mortality_rate': float(cohort_final['disposition'].mean()),\n",
    "    'date_range': {\n",
    "        'start': cohort_final['start_dttm'].min().isoformat(),\n",
    "        'end': cohort_final['start_dttm'].max().isoformat()\n",
    "    },\n",
    "    'criteria': {\n",
    "        'min_age': 18,\n",
    "        'years': '2020-2021',\n",
    "        'icu_window': '48_hours_from_admission',\n",
    "        'min_icu_duration': '24_hours',\n",
    "        'icu_or_icu_handling': 'continuous_icu'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join('..', 'output', 'preprocessing', 'cohort_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✅ Metadata saved to: {metadata_path}\")\n",
    "print(\"\\n🎉 Cohort generation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flameICU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
