{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICU Mortality Model - Feature Engineering\n",
    "\n",
    "This notebook loads the ICU cohort and creates hourly wide dataset for the first 24 hours of ICU stay.\n",
    "\n",
    "## Objective\n",
    "- Load ICU cohort from 01_cohort.ipynb\n",
    "- Use pyCLIF to extract features from CLIF tables\n",
    "- Create hourly wide dataset for the first 24 hours\n",
    "- Filter to encounters with complete 24-hour data\n",
    "- Save features for modeling\n",
    "\n",
    "## Feature Sources\n",
    "- **Vitals**: All vital_category values\n",
    "- **Labs**: All lab_category values\n",
    "- **Patient Assessments**: GCS_total, RASS\n",
    "- **Respiratory Support**: Mode, FiO2, PEEP, ventilator settings (with one-hot encoding)\n",
    "- **Medications**: All vasoactives and sedatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyclif import CLIF\n",
    "from pyclif.utils.wide_dataset import convert_wide_to_hourly\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== ICU Mortality Model - Feature Engineering ===\")\n",
    "print(\"Setting up environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"Load configuration from config.json\"\"\"\n",
    "    config_path = os.path.join(\"config_demo.json\")\n",
    "    \n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = json.load(file)\n",
    "        print(\"✅ Loaded configuration from config.json\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Configuration file not found. Please create config.json based on the config_template.\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Load configuration\n",
    "config = load_config()\n",
    "print(f\"Site: {config['site']}\")\n",
    "print(f\"Data path: {config['clif2_path']}\")\n",
    "print(f\"File type: {config['filetype']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyCLIF\n",
    "clif = CLIF(\n",
    "    data_dir=config['clif2_path'],\n",
    "    filetype=config['filetype'],\n",
    "    timezone=\"US/Eastern\"\n",
    ")\n",
    "\n",
    "print(\"✅ pyCLIF initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ICU Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ICU cohort from 01_cohort.ipynb\n",
    "cohort_path = os.path.join('output', 'intermitted', 'icu_cohort.csv')\n",
    "\n",
    "if os.path.exists(cohort_path):\n",
    "    cohort_df = pd.read_csv(cohort_path)\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    datetime_cols = ['start_dttm', 'hour_24_start_dttm', 'hour_24_end_dttm']\n",
    "    for col in datetime_cols:\n",
    "        cohort_df[col] = pd.to_datetime(cohort_df[col])\n",
    "    \n",
    "    print(f\"✅ Loaded ICU cohort: {len(cohort_df)} hospitalizations\")\n",
    "    print(f\"Mortality rate: {cohort_df['disposition'].mean():.3f}\")\n",
    "    print(f\"Time range: {cohort_df['start_dttm'].min()} to {cohort_df['start_dttm'].max()}\")\n",
    "    \n",
    "else:\n",
    "    raise FileNotFoundError(f\"Cohort file not found at {cohort_path}. Please run 01_cohort.ipynb first.\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample cohort records:\")\n",
    "print(cohort_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction configuration\n",
    "print(\"Configuring feature extraction...\")\n",
    "\n",
    "# Get hospitalization IDs from cohort\n",
    "cohort_ids = cohort_df['hospitalization_id'].astype(str).unique().tolist()\n",
    "print(f\"Extracting features for {len(cohort_ids)} hospitalizations\")\n",
    "\n",
    "# Define category filters for each table\n",
    "category_filters = {\n",
    "    'vitals': [  # Common vital signs\n",
    "        'heart_rate', 'map', 'respiratory_rate', 'spo2', 'temp_c',\n",
    "        'weight_kg', 'height_cm'\n",
    "    ],\n",
    "    'labs': [  # Common lab values\n",
    "        \"albumin\",    \"alkaline_phosphatase\",    \"alt\",    \"ast\",    \"basophils_percent\",    \"basophils_absolute\",    \"bicarbonate\",    \"bilirubin_total\",    \"bilirubin_conjugated\",    \"bilirubin_unconjugated\",\n",
    "    \"bun\",\n",
    "    \"calcium_total\",    \"calcium_ionized\",    \"chloride\",    \"creatinine\",    \"crp\",    \"eosinophils_percent\",\n",
    "    \"eosinophils_absolute\",    \"esr\",    \"ferritin\",    \"glucose_fingerstick\",    \"glucose_serum\",    \"hemoglobin\",    \"phosphate\",    \"inr\",    \"lactate\",    \"ldh\",\n",
    "    \"lymphocytes_percent\",    \"lymphocytes_absolute\",    \"magnesium\",    \"monocytes_percent\",    \"monocytes_absolute\",    \"neutrophils_percent\",    \"neutrophils_absolute\",\n",
    "    \"pco2_arterial\",    \"po2_arterial\",    \"pco2_venous\",    \"ph_arterial\",    \"ph_venous\",    \"platelet_count\",    \"potassium\",    \"procalcitonin\",\n",
    "    \"pt\",    \"ptt\",    \"so2_arterial\",    \"so2_mixed_venous\",    \"so2_central_venous\",    \"sodium\",\n",
    "    \"total_protein\",    \"troponin_i\",    \"troponin_t\",    \"wbc\"\n",
    "    ],\n",
    "    'patient_assessments': [  # Neurological assessments\n",
    "        'gcs_total', 'rass'\n",
    "    ],\n",
    "    'medication_admin_continuous': [  # Vasoactives and sedatives\n",
    "        \"norepinephrine\",\n",
    "    \"epinephrine\",\n",
    "    \"phenylephrine\",\n",
    "    \"angiotensin\",\n",
    "    \"vasopressin\",\n",
    "    \"dopamine\",\n",
    "    \"dobutamine\",\n",
    "    \"milrinone\",\n",
    "    \"isoproterenol\",\n",
    "    \"propofol\",\n",
    "    \"dexmedetomidine\",\n",
    "    \"ketamine\",\n",
    "    \"midazolam\",\n",
    "    \"fentanyl\",\n",
    "    \"hydromorphone\",\n",
    "    \"morphine\",\n",
    "    \"remifentanil\",\n",
    "    \"pentobarbital\",\n",
    "    \"lorazepam\"\n",
    "    ],\n",
    "    'respiratory_support': [  # All respiratory support categories\n",
    "        'mode_category', 'device_category', 'fio2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Feature extraction configuration:\")\n",
    "for table, categories in category_filters.items():\n",
    "    print(f\"  {table}: {len(categories)} categories\")\n",
    "    print(f\"    {categories[:5]}...\" if len(categories) > 5 else f\"    {categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Wide Dataset Using pyCLIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wide dataset for cohort hospitalizations\n",
    "print(\"Creating wide dataset using pyCLIF...\")\n",
    "\n",
    "\n",
    "wide_df = clif.create_wide_dataset(\n",
    "    hospitalization_ids=cohort_ids,\n",
    "    optional_tables=['vitals', 'labs', 'patient_assessments', 'medication_admin_continuous', 'respiratory_support'],\n",
    "    category_filters=category_filters,\n",
    "    save_to_data_location=False  # Keep in memory for processing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.to_csv(\"wide_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to 24-Hour Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter wide dataset to 24-hour windows\n",
    "print(\"Filtering to 24-hour windows...\")\n",
    "cohort_df['hospitalization_id'] = cohort_df['hospitalization_id'].astype(str)\n",
    "# Merge with cohort to get time windows\n",
    "wide_df_filtered = pd.merge(\n",
    "    wide_df,\n",
    "    cohort_df[['hospitalization_id', 'hour_24_start_dttm', 'hour_24_end_dttm', 'disposition']],\n",
    "    on='hospitalization_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"After merge with cohort: {len(wide_df_filtered)} records\")\n",
    "\n",
    "# Filter events within 24-hour window\n",
    "wide_df_filtered = wide_df_filtered[\n",
    "    (wide_df_filtered['event_time'] >= wide_df_filtered['hour_24_start_dttm']) &\n",
    "    (wide_df_filtered['event_time'] <= wide_df_filtered['hour_24_end_dttm'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Filtered to 24-hour windows: {len(wide_df_filtered)} records\")\n",
    "print(f\"Hospitalizations with data: {wide_df_filtered['hospitalization_id'].nunique()}\")\n",
    "\n",
    "# Show time window validation\n",
    "print(\"\\nTime window validation:\")\n",
    "print(f\"All events within window: {((wide_df_filtered['event_time'] >= wide_df_filtered['hour_24_start_dttm']) & (wide_df_filtered['event_time'] <= wide_df_filtered['hour_24_end_dttm'])).all()}\")\n",
    "print(f\"Average records per hospitalization: {len(wide_df_filtered) / wide_df_filtered['hospitalization_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df_filtered.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_config = {\n",
    "    'max': ['eosinophils_absolute',\n",
    " 'glucose_fingerstick',\n",
    " 'lymphocytes_absolute',\n",
    " 'monocytes_absolute',\n",
    " 'neutrophils_absolute',\n",
    " 'procalcitonin',\n",
    " 'troponin_i',\n",
    " 'wbc',\n",
    " 'gcs_total',\n",
    " 'rass',\n",
    " 'angiotensin',\n",
    " 'isoproterenol',\n",
    " 'ketamine',\n",
    " 'remifentanil',\n",
    " 'pentobarbital',\n",
    " 'lorazepam',\n",
    " 'fio2'],\n",
    "    'min': ['eosinophils_absolute',\n",
    " 'glucose_fingerstick',\n",
    " 'lymphocytes_absolute',\n",
    " 'monocytes_absolute',\n",
    " 'neutrophils_absolute',\n",
    " 'procalcitonin',\n",
    " 'troponin_i',\n",
    " 'wbc',\n",
    " 'gcs_total',\n",
    " 'rass',\n",
    " 'angiotensin',\n",
    " 'isoproterenol',\n",
    " 'ketamine',\n",
    " 'remifentanil',\n",
    " 'pentobarbital',\n",
    " 'lorazepam',\n",
    " 'fio2'],\n",
    "    'mean': ['eosinophils_absolute',\n",
    " 'glucose_fingerstick',\n",
    " 'lymphocytes_absolute',\n",
    " 'monocytes_absolute',\n",
    " 'neutrophils_absolute',\n",
    " 'procalcitonin',\n",
    " 'troponin_i',\n",
    " 'wbc',\n",
    " 'gcs_total',\n",
    " 'rass',\n",
    " 'angiotensin',\n",
    " 'isoproterenol',\n",
    " 'ketamine',\n",
    " 'remifentanil',\n",
    " 'pentobarbital',\n",
    " 'lorazepam',\n",
    " 'fio2'],\n",
    "    'median': ['eosinophils_absolute',\n",
    " 'glucose_fingerstick',\n",
    " 'lymphocytes_absolute',\n",
    " 'monocytes_absolute',\n",
    " 'neutrophils_absolute',\n",
    " 'procalcitonin',\n",
    " 'troponin_i',\n",
    " 'wbc',\n",
    " 'gcs_total',\n",
    " 'rass',\n",
    " 'angiotensin',\n",
    " 'isoproterenol',\n",
    " 'ketamine',\n",
    " 'remifentanil',\n",
    " 'pentobarbital',\n",
    " 'lorazepam',\n",
    " 'fio2',],\n",
    "    'boolean': ['eosinophils_absolute',\n",
    " 'glucose_fingerstick',\n",
    " 'lymphocytes_absolute',\n",
    " 'monocytes_absolute',\n",
    " 'neutrophils_absolute',\n",
    " 'procalcitonin',\n",
    " 'troponin_i',\n",
    " 'wbc',\n",
    " 'gcs_total',\n",
    " 'rass',\n",
    " 'angiotensin',\n",
    " 'isoproterenol',\n",
    " 'ketamine',\n",
    " 'remifentanil',\n",
    " 'pentobarbital',\n",
    " 'lorazepam',\n",
    " 'fio2',],\n",
    "    'one_hot_encode': [ 'mode_category','device_category']\n",
    "}\n",
    "\n",
    "hourly_df = convert_wide_to_hourly(wide_df, aggregation_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "output_dir = os.path.join('output', 'intermitted')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.to_parquet(os.path.join(output_dir, 'by_event_wide_df.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df.to_parquet(os.path.join(output_dir, 'by_hourly_wide_df.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
